import streamlit as st
import speech_recognition as sr
import json
import threading
import os
from gtts import gTTS
import pygame
import time
from openai import OpenAI
import langdetect
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# OpenAI API í‚¤ ì„¤ì •
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

client = OpenAI(api_key=OPENAI_API_KEY)

# ìƒíƒœ ê´€ë¦¬ ì´ˆê¸°í™”
if "input_text" not in st.session_state:
    st.session_state.input_text = ""
if "output_text" not in st.session_state:
    st.session_state.output_text = ""
if "audio_file" not in st.session_state:
    st.session_state.audio_file = None
if "detected_language" not in st.session_state:
    st.session_state.detected_language = None

def detect_language(text):
    """
    í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ë¥¼ ê°ì§€í•˜ëŠ” í•¨ìˆ˜
    Returns language code and language name
    """
    try:
        detected = langdetect.detect(text)
        # ì–¸ì–´ ì½”ë“œì™€ í•´ë‹¹í•˜ëŠ” ì–¸ì–´ ì´ë¦„ì„ ë°˜í™˜
        language_names = {
            'ko': 'í•œêµ­ì–´',
            'en': 'ì˜ì–´',
            'ja': 'ì¼ë³¸ì–´',
            'zh-cn': 'ì¤‘êµ­ì–´',
            'es': 'ìŠ¤í˜ì¸ì–´',
            'fr': 'í”„ë‘ìŠ¤ì–´',
            'de': 'ë…ì¼ì–´',
            'ru': 'ëŸ¬ì‹œì•„ì–´',
            'vi': 'ë² íŠ¸ë‚¨ì–´',
            'th': 'íƒœêµ­ì–´',
            'ar': 'ì•„ëì–´',
            'hi': 'íŒë””ì–´',
            'pt': 'í¬ë¥´íˆ¬ê°ˆì–´',
            'it': 'ì´íƒˆë¦¬ì•„ì–´'
        }
        return detected, language_names.get(detected, detected)
    except:
        return "en", "ì˜ì–´"  # ê¸°ë³¸ê°’ìœ¼ë¡œ ì˜ì–´ ë°˜í™˜

def get_tts_language(lang_code):
    """
    TTSì— ì‚¬ìš©í•  ì–¸ì–´ ì½”ë“œ ë°˜í™˜
    """
    if lang_code == "ko":
        return "ko"
    return "en"

def recognize_speech():
    """
    ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
    """
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        st.info("ğŸ¤ ë§ì”€í•´ ì£¼ì„¸ìš”... (ë§ˆì´í¬ ì¡°ì • ì¤‘)")
        recognizer.adjust_for_ambient_noise(source)
        st.info("ğŸ¤ ì´ì œ ë§ì”€í•˜ì„¸ìš”!")
        audio = recognizer.listen(source, timeout=5)
        st.info("âœ¨ ìŒì„± ì²˜ë¦¬ ì¤‘...")

    try:
        # ë¨¼ì € í•œêµ­ì–´ë¡œ ì¸ì‹ ì‹œë„
        try:
            text = recognizer.recognize_google(audio, language="ko-KR")
        except:
            # í•œêµ­ì–´ ì¸ì‹ ì‹¤íŒ¨ ì‹œ ì˜ì–´ë¡œ ì‹œë„
            text = recognizer.recognize_google(audio, language="en-US")
        return text
    except sr.UnknownValueError:
        st.error("âŒ ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return None
    except sr.RequestError:
        st.error("âŒ ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
        return None

def translate_text(text, source_lang):
    """
    OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ë²ˆì—­í•˜ëŠ” í•¨ìˆ˜
    """
    if source_lang == "en":
        prompt = f"Translate the following English text to Korean, preserving any proper nouns: '{text}'"
    else:
        prompt = f"Translate the following {source_lang} text to English. The input text is: '{text}'"
    
    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a professional translator. Translate the text naturally while preserving the original meaning."},
                {"role": "user", "content": prompt}
            ]
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"ë²ˆì—­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return None

def handle_translation(input_text):
    """
    ë²ˆì—­ ì²˜ë¦¬ì™€ ìŒì„± ë³€í™˜ì„ ê´€ë¦¬í•˜ëŠ” í•¨ìˆ˜
    """
    source_lang, source_lang_name = detect_language(input_text)
    st.session_state.detected_language = source_lang
    
    # í…ìŠ¤íŠ¸ ë²ˆì—­
    translated_text = translate_text(input_text, source_lang)
    if translated_text:
        st.session_state.output_text = translated_text
        
        # ë²ˆì—­ëœ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜
        target_lang = "ko" if source_lang == "en" else "en"
        try:
            tts = gTTS(text=translated_text, lang=get_tts_language(target_lang))
            audio_file = "output.mp3"
            tts.save(audio_file)
            st.session_state.audio_file = audio_file
        except Exception as e:
            st.error(f"ìŒì„± ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

def play_audio(file_path):
    """
    ìŒì„± íŒŒì¼ ì¬ìƒ í•¨ìˆ˜
    """
    pygame.mixer.init()
    pygame.mixer.music.load(file_path)
    pygame.mixer.music.play()
    while pygame.mixer.music.get_busy():
        time.sleep(0.1)

# Streamlit UI
st.set_page_config(
    page_title="AI ì‹¤ì‹œê°„ ìŒì„± ë²ˆì—­ê¸°",
    page_icon="ğŸ¯",
    layout="centered"
)

st.title("ğŸŒ AI ì‹¤ì‹œê°„ ìŒì„± ë²ˆì—­ê¸°")
st.markdown("""
    ### ì‚¬ìš© ë°©ë²•
    1. 'ìŒì„± ë…¹ìŒ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
    2. ë§ˆì´í¬ì— ë§ì”€í•´ ì£¼ì„¸ìš”
    3. ìë™ìœ¼ë¡œ ì–¸ì–´ë¥¼ ê°ì§€í•˜ì—¬ ë²ˆì—­í•©ë‹ˆë‹¤
    - ì˜ì–´ â†’ í•œêµ­ì–´
    - ê·¸ ì™¸ ì–¸ì–´ â†’ ì˜ì–´
""")

col1, col2 = st.columns(2)
with col1:
    if st.button("ğŸ¤ ìŒì„± ë…¹ìŒ ì‹œì‘", key="record"):
        input_text = recognize_speech()
        if input_text:
            st.session_state.input_text = input_text
            handle_translation(input_text)

with col2:
    if st.session_state.audio_file and os.path.exists(st.session_state.audio_file):
        if st.button("ğŸ”Š ë²ˆì—­ ìŒì„± ì¬ìƒ", key="play"):
            play_audio(st.session_state.audio_file)

if st.session_state.input_text:
    st.markdown("### ğŸ“ ì…ë ¥ëœ í…ìŠ¤íŠ¸")
    st.info(st.session_state.input_text)
    if st.session_state.detected_language:
        source_lang, source_lang_name = detect_language(st.session_state.input_text)
        st.caption(f"ê°ì§€ëœ ì–¸ì–´: {source_lang_name}")

if st.session_state.output_text:
    st.markdown("### ğŸ”„ ë²ˆì—­ëœ í…ìŠ¤íŠ¸")
    st.success(st.session_state.output_text)
    target_lang = "í•œêµ­ì–´" if st.session_state.detected_language == "en" else "ì˜ì–´"
    st.caption(f"ë²ˆì—­ëœ ì–¸ì–´: {target_lang}")

# ì˜¤ë””ì˜¤ íŒŒì¼ í‘œì‹œ
if st.session_state.audio_file and os.path.exists(st.session_state.audio_file):
    st.markdown("### ğŸµ ë²ˆì—­ëœ ìŒì„±")
    with open(st.session_state.audio_file, "rb") as file:
        st.audio(file.read(), format="audio/mp3")

# ì•± ì¢…ë£Œ ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë¦¬
if st.session_state.audio_file and os.path.exists(st.session_state.audio_file):
    os.remove(st.session_state.audio_file)
    st.session_state.audio_file = None